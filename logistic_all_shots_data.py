# -*- coding: utf-8 -*-
"""Logistic_all_shots_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13AUpS9MhSYHewwJskfkxxV0RCe9IkloX
"""

import pandas as pd
import string
import nltk
import joblib
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Download NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

excel_file_path = 'GPT generated data.xlsx'

# Load the "All_shots_data" sheet
sheet_name = 'All_shots_data'
all_shots_data = pd.read_excel(excel_file_path, sheet_name=sheet_name)

# Prepare the data directly
data_cleaned = all_shots_data[['Chart Title', 'Sentence', 'Stage']].dropna()

# Label Creation
data_cleaned['Label'] = data_cleaned['Stage'].apply(lambda x: 0 if x == 1 else 1)

# Feature Engineering
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data_cleaned['Sentence'])
y = data_cleaned['Label']
chart_titles = data_cleaned['Chart Title']

# Initialize Logistic Regression model
model = LogisticRegression()

# Cross-Validation Evaluation
cv_accuracy = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()
cv_f1 = cross_val_score(model, X, y, cv=5, scoring='f1').mean()
cv_auc = cross_val_score(model, X, y, cv=5, scoring='roc_auc').mean()

# Leave-One-Plot-Out Evaluation
unique_charts = chart_titles.unique()
accuracy_scores = []
f1_scores = []
auc_scores = []

for chart in unique_charts:
    test_index = data_cleaned['Chart Title'] == chart
    train_index = ~test_index

    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]

    accuracy_scores.append(accuracy_score(y_test, y_pred))
    f1_scores.append(f1_score(y_test, y_pred, zero_division=0))

    if len(set(y_test)) > 1:
        auc_scores.append(roc_auc_score(y_test, y_prob))

lopo_accuracy = sum(accuracy_scores) / len(accuracy_scores)
lopo_f1 = sum(f1_scores) / len(f1_scores)
lopo_auc = sum(auc_scores) / len(auc_scores) if auc_scores else 'N/A'

#Results
results = {
    "Version": "All_shots_data",
    "Model": "Logistic Regression",
    "CV_AUC": cv_auc,
    "CV_Accuracy": cv_accuracy,
    "CV_F1": cv_f1,
    "LOPO_AUC": lopo_auc,
    "LOPO_Accuracy": lopo_accuracy,
    "LOPO_F1": lopo_f1
}

# Save the trained model and vectorizer
joblib.dump(model, 'LogisticRegression_All_shots_data_model.pkl')
joblib.dump(vectorizer, 'LogisticRegression_All_shots_data_vectorizer.pkl')

# Print results
print(f"Cross-Validation Results: AUC={cv_auc}, Accuracy={cv_accuracy}, F1={cv_f1}")
print(f"LOPO Results: AUC={lopo_auc}, Accuracy={lopo_accuracy}, F1={lopo_f1}")



